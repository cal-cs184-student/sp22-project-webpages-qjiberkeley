<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_tfnvj3r6dq5t-0>li:before{content:"\0025cf  "}.lst-kix_tfnvj3r6dq5t-2>li:before{content:"\0025a0  "}.lst-kix_tfnvj3r6dq5t-3>li:before{content:"\0025cf  "}ul.lst-kix_tfnvj3r6dq5t-8{list-style-type:none}ul.lst-kix_tfnvj3r6dq5t-7{list-style-type:none}ul.lst-kix_tfnvj3r6dq5t-6{list-style-type:none}.lst-kix_tfnvj3r6dq5t-1>li:before{content:"\0025cb  "}.lst-kix_tfnvj3r6dq5t-5>li:before{content:"\0025a0  "}ul.lst-kix_tfnvj3r6dq5t-1{list-style-type:none}ul.lst-kix_tfnvj3r6dq5t-0{list-style-type:none}ul.lst-kix_tfnvj3r6dq5t-5{list-style-type:none}.lst-kix_tfnvj3r6dq5t-4>li:before{content:"\0025cb  "}ul.lst-kix_tfnvj3r6dq5t-4{list-style-type:none}ul.lst-kix_tfnvj3r6dq5t-3{list-style-type:none}ul.lst-kix_tfnvj3r6dq5t-2{list-style-type:none}.lst-kix_3zg7cputjo79-6>li:before{content:"\0025cf  "}.lst-kix_3zg7cputjo79-7>li:before{content:"\0025cb  "}.lst-kix_3zg7cputjo79-8>li:before{content:"\0025a0  "}ul.lst-kix_3zg7cputjo79-6{list-style-type:none}ul.lst-kix_3zg7cputjo79-5{list-style-type:none}ul.lst-kix_3zg7cputjo79-4{list-style-type:none}ul.lst-kix_3zg7cputjo79-3{list-style-type:none}ul.lst-kix_3zg7cputjo79-2{list-style-type:none}.lst-kix_3zg7cputjo79-5>li:before{content:"\0025a0  "}ul.lst-kix_3zg7cputjo79-1{list-style-type:none}ul.lst-kix_3zg7cputjo79-0{list-style-type:none}.lst-kix_3zg7cputjo79-4>li:before{content:"\0025cb  "}.lst-kix_x2ablpql3w33-6>li:before{content:"\0025cf  "}.lst-kix_3zg7cputjo79-3>li:before{content:"\0025cf  "}.lst-kix_x2ablpql3w33-5>li:before{content:"\0025a0  "}.lst-kix_x2ablpql3w33-7>li:before{content:"\0025cb  "}ul.lst-kix_x2ablpql3w33-0{list-style-type:none}ul.lst-kix_x2ablpql3w33-1{list-style-type:none}.lst-kix_3zg7cputjo79-2>li:before{content:"\0025a0  "}ul.lst-kix_3zg7cputjo79-8{list-style-type:none}ul.lst-kix_x2ablpql3w33-2{list-style-type:none}ul.lst-kix_3zg7cputjo79-7{list-style-type:none}.lst-kix_x2ablpql3w33-8>li:before{content:"\0025a0  "}.lst-kix_3zg7cputjo79-1>li:before{content:"\0025cb  "}.lst-kix_3zg7cputjo79-0>li:before{content:"\0025cf  "}.lst-kix_x2ablpql3w33-2>li:before{content:"\0025a0  "}ul.lst-kix_x2ablpql3w33-3{list-style-type:none}ul.lst-kix_x2ablpql3w33-4{list-style-type:none}.lst-kix_tfnvj3r6dq5t-6>li:before{content:"\0025cf  "}.lst-kix_tfnvj3r6dq5t-7>li:before{content:"\0025cb  "}.lst-kix_x2ablpql3w33-3>li:before{content:"\0025cf  "}ul.lst-kix_x2ablpql3w33-5{list-style-type:none}ul.lst-kix_x2ablpql3w33-6{list-style-type:none}.lst-kix_x2ablpql3w33-4>li:before{content:"\0025cb  "}ul.lst-kix_x2ablpql3w33-7{list-style-type:none}ul.lst-kix_x2ablpql3w33-8{list-style-type:none}.lst-kix_tfnvj3r6dq5t-8>li:before{content:"\0025a0  "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_x2ablpql3w33-1>li:before{content:"\0025cb  "}.lst-kix_x2ablpql3w33-0>li:before{content:"\0025cf  "}ol{margin:0;padding:0}table td,table th{padding:0}.c9{border-right-style:solid;padding-top:4.4pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:4.4pt;line-height:1.0;border-top-style:solid;margin-left:144pt;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:left;padding-right:0pt}.c7{border-right-style:solid;padding-top:4.4pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:4.4pt;line-height:1.0;border-top-style:solid;margin-left:108pt;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:left;padding-right:0pt}.c15{border-right-style:solid;padding-top:4.4pt;border-top-width:0pt;border-right-width:0pt;padding-bottom:4.4pt;line-height:1.0;border-top-style:solid;margin-left:72pt;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:left;padding-right:0pt}.c10{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:234pt;border-top-color:#000000;border-bottom-style:solid}.c23{margin-left:36pt;padding-top:0pt;padding-bottom:5pt;line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:center}.c0{margin-left:36pt;padding-top:0pt;padding-bottom:2pt;line-height:1.0;orphans:2;widows:2;text-align:left;height:11pt}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Arial";font-style:normal}.c14{margin-left:108pt;padding-top:0pt;padding-bottom:2pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c2{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c17{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c8{padding-top:0pt;padding-bottom:2pt;line-height:1.0;orphans:2;widows:2;text-align:left;height:11pt}.c27{margin-left:144pt;padding-top:0pt;padding-bottom:2pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c13{margin-left:72pt;padding-top:0pt;padding-bottom:2pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c4{margin-left:36pt;padding-top:0pt;padding-bottom:2pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c21{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c12{margin-left:72pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c19{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;text-decoration:underline}.c24{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c20{color:inherit;text-decoration:inherit}.c5{padding:0;margin:0}.c25{font-size:12pt;color:#333333}.c22{font-style:italic}.c28{height:11pt}.c11{padding-left:0pt}.c26{margin-left:72pt}.c3{font-weight:700}.c18{height:0pt}.c16{text-indent:36pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c24"><h1 class="c23" id="h.nm75jk2fzypz"><span class="c6">CS184 Final Project Proposal</span></h1><ul class="c5 lst-kix_3zg7cputjo79-0 start"><li class="c4 c11 li-bullet-0"><span class="c2">Title, Summary and Team Members</span></li></ul><ul class="c5 lst-kix_3zg7cputjo79-1 start"><li class="c13 c11 li-bullet-0"><span class="c3">Title:</span><span class="c1">&nbsp;Path Tracing Lenses and Contrast-based Autofocus</span></li><li class="c13 c11 li-bullet-0"><span class="c3">Summary: </span><span class="c1">&nbsp;In our final project, we want to implement an extension of Project 3, which will enable autofocus to mimic a camera in reality. The main idea is ray tracing, and we will implement ray tracing for both mirror and glass materials and microfacet materials.</span></li><li class="c11 c13 li-bullet-0"><span class="c3">Team members: </span><span class="c1">Qingsong Ji, Lauren Leung, Shuyao Zhou, and Haodi Zou.</span></li></ul><p class="c8"><span class="c1"></span></p><ul class="c5 lst-kix_3zg7cputjo79-0"><li class="c4 c11 li-bullet-0"><span class="c3">Problem Description</span></li></ul><ul class="c5 lst-kix_3zg7cputjo79-1 start"><li class="c13 c11 li-bullet-0"><span class="c3">Context: </span><span class="c1">In Project 3-Part 4, we are supposed to enable depth of field effect using a single thin lens. In the final project, we will extend it to multiple lenses to mimic a camera in reality so that we can create more artistic outcomes with some images focusing on objects and other images focusing on backgrounds. This task is challenging in implementing the autofocus part because we need to consider the object&rsquo;s relative positions to the lenses. We are going to solve this problem with the ray tracing algorithms we learned in relevant papers. </span></li></ul><p class="c8"><span class="c1"></span></p><ul class="c5 lst-kix_3zg7cputjo79-0"><li class="c4 c11 li-bullet-0"><span class="c3">Goals and Deliverables</span></li></ul><ul class="c5 lst-kix_3zg7cputjo79-1 start"><li class="c13 c11 li-bullet-0"><span class="c3">The </span><span class="c3">kind of images we will create:</span></li></ul><ul class="c5 lst-kix_3zg7cputjo79-2 start"><li class="c11 c14 li-bullet-0"><span class="c1">Our goal is to implement ray tracing through compound lenses and also contrast-based autofocus. We will show these results through pngs of image renders. We will show some examples of images through different lenses, with and without autofocus. We will also show some examples of images with the naive implementation of contrast-based autofocus as described in the Sp16 Project 3-2 spec, and our improved algorithm.</span></li><li class="c14 c11 li-bullet-0"><span class="c1">The new lighting effect with compound lenses:</span></li></ul><p class="c14"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 310.50px; height: 206.12px;"><img alt="" src="images/image5.png" style="width: 310.50px; height: 206.12px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ul class="c5 lst-kix_3zg7cputjo79-1"><li class="c13 c11 li-bullet-0"><span class="c3">H</span><span class="c3">ow we will measure the quality / performance of our system:</span></li></ul><ul class="c5 lst-kix_3zg7cputjo79-2 start"><li class="c14 c11 li-bullet-0"><span class="c1">We will measure the quality and speed of our contrast autofocus algorithm by comparing how long it takes to complete versus the naive implementation. At this time, we hope to achieve &gt; 2x speed up and quality increase that is visually discernible. </span></li></ul><ul class="c5 lst-kix_3zg7cputjo79-1"><li class="c13 c11 li-bullet-0"><span class="c3">Q</span><span class="c3">uestions we plan to answer</span><span class="c2">&nbsp;with our analysis:</span></li></ul><ul class="c5 lst-kix_3zg7cputjo79-2 start"><li class="c14 c11 li-bullet-0"><span class="c1">What formulas to use on compound lenses?</span></li><li class="c14 c11 li-bullet-0"><span class="c1">What are some effective ways to modify the search algorithm to find the best sensor depth for the current image patch?</span></li><li class="c14 c11 li-bullet-0"><span class="c1">What are some effective ways to modify the focus metric? </span></li><li class="c14 c11 li-bullet-0"><span class="c1">Will autofocus perform better on microfacet materials than glass materials?</span></li></ul><ul class="c5 lst-kix_3zg7cputjo79-1"><li class="c13 c11 li-bullet-0"><span class="c2">Planning:</span></li></ul><p class="c13"><span class="c3">(1) Plan to deliver: (</span><span class="c3 c25">baseline plan)</span></p><p class="c15"><span class="c2">Part 1: Tracing Rays through Lenses</span></p><ul class="c5 lst-kix_x2ablpql3w33-0 start"><li class="c7 li-bullet-0"><span class="c1">Task 1: Tracing</span></li></ul><ul class="c5 lst-kix_x2ablpql3w33-1 start"><li class="c9 li-bullet-0"><span class="c1">Intersect the ray with the spherical lens element</span></li><li class="c9 li-bullet-0"><span class="c1">Refract the ray using Snell&#39;s law</span></li></ul><ul class="c5 lst-kix_x2ablpql3w33-0"><li class="c7 li-bullet-0"><span class="c1">Task 2: Lens and LensCamera helper functions</span></li></ul><ul class="c5 lst-kix_x2ablpql3w33-1 start"><li class="c9 li-bullet-0"><span class="c1">Set focus parameters by calculating infinity_focus, near_focus, and focal_length</span></li><li class="c9 li-bullet-0"><span class="c1">Compute the object-side conjugate of a sensor depth</span></li><li class="c9 li-bullet-0"><span class="c1">Sample on the 2D circle corresponding to the back of the lens element nearest the sensor</span></li><li class="c9 li-bullet-0"><span class="c1">Generate a ray from the given sensor position and then trace it through the lens.</span></li></ul><p class="c15"><span class="c3">Expected rendering results:</span></p><a id="t.34c968869fbbdaac8fff0fec79919d98042a1192"></a><a id="t.0"></a><table class="c12"><tbody><tr class="c18"><td class="c10" colspan="1" rowspan="1"><p class="c21"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 250.00px; height: 166.67px;"><img alt="" src="images/image3.png" style="width: 250.00px; height: 166.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c21"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 250.00px; height: 166.67px;"><img alt="" src="images/image4.png" style="width: 250.00px; height: 166.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c18"><td class="c10" colspan="1" rowspan="1"><p class="c21"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 250.00px; height: 166.67px;"><img alt="" src="images/image1.png" style="width: 250.00px; height: 166.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c21"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 250.00px; height: 166.67px;"><img alt="" src="images/image2.png" style="width: 250.00px; height: 166.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr></tbody></table><p class="c15 c28"><span class="c1"></span></p><p class="c15"><span class="c2">Part 2: Contrast-based Autofocus</span></p><ul class="c5 lst-kix_tfnvj3r6dq5t-0 start"><li class="c7 li-bullet-0"><span class="c1">Task 1: A simple focus metric - variance</span></li></ul><ul class="c5 lst-kix_tfnvj3r6dq5t-1 start"><li class="c9 li-bullet-0"><span>Implement the function </span><span class="c22">focus_metric</span><span>, which</span><span>&nbsp;</span><span class="c1">takes an ImageBuffer instance and computes the focus metric of it</span></li><li class="c9 li-bullet-0"><span class="c1">The focus metric is a value that is higher when the image is more in focus (sharper) and lower when the image is less in focus (blurrier)</span></li><li class="c9 li-bullet-0"><span>In this task, the focus metric should be equal to the variance of the image patch</span></li></ul><ul class="c5 lst-kix_tfnvj3r6dq5t-0"><li class="c7 li-bullet-0"><span class="c1">Task 2: Autofocus search</span></li></ul><ul class="c5 lst-kix_tfnvj3r6dq5t-1 start"><li class="c9 li-bullet-0"><span>Implement the function </span><span class="c22">autofocus</span><span class="c1">, which estimates the depth where the image patch has the highest focus metric</span></li><li class="c9 li-bullet-0"><span>Step through all valid sensor depths and set </span><span class="c22">curr_lens().sensor_depth </span><span class="c1">to be the depth where the focus metric is the largest</span></li></ul><p class="c15"><span class="c3">Expected rendering results:</span></p><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 331.02px; height: 221.02px;"><img alt="" src="images/image5.png" style="width: 331.02px; height: 221.02px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c13"><span class="c3">(2) Hope to deliver: (</span><span class="c25 c3">aspirational plan)</span></p><p class="c13"><span class="c2">Part 3: Faster contrast-based autofocus</span></p><ul class="c5 lst-kix_tfnvj3r6dq5t-0"><li class="c7 li-bullet-0"><span class="c1">Improve the quality and speed of our contrast-based autofocus algorithm.</span></li></ul><ul class="c5 lst-kix_tfnvj3r6dq5t-1 start"><li class="c9 li-bullet-0"><span class="c1">Improve the search algorithm by implement a non-uniform or recursive scheme for finding the focus position with fewer image patch renders or other acceleration techniques</span></li><li class="c9 li-bullet-0"><span class="c1">Build a more robust focus metric based on the Sum-Modified Laplacian metric</span></li><li class="c9 li-bullet-0"><span class="c1">Use a total variation metric to reduce noise and render more efficiently with fewer samples</span></li></ul><p class="c8"><span class="c1"></span></p><ul class="c5 lst-kix_3zg7cputjo79-0"><li class="c4 c11 li-bullet-0"><span class="c2">Schedule</span></li></ul><ul class="c5 lst-kix_3zg7cputjo79-1 start"><li class="c13 c11 li-bullet-0"><span class="c3">Organize and plan the tasks and subtasks:</span></li></ul><ul class="c5 lst-kix_3zg7cputjo79-2 start"><li class="c14 c11 li-bullet-0"><span class="c2">Week 1 (4/10-4/16):</span></li></ul><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mon 4/11: proposal due</span></p><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Finish Part 1 Tracing Rays through Lenses by 4/16:</span></p><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Task 1: Tracing rays through lenses (refract the ray)</span></p><p class="c14 c16"><span class="c1">Task 2: Lens and LensCamera helper functions</span></p><p class="c8"><span class="c1"></span></p><ul class="c5 lst-kix_3zg7cputjo79-2"><li class="c14 c11 li-bullet-0"><span class="c2">Week 2 (4/17-4/23):</span></li></ul><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Finish Part 2 Contrast-based Autofocus by 4/23:</span></p><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Task 1: A simple focus metric - variance</span></p><p class="c14 c16"><span class="c1">Task 2: Autofocus search</span></p><p class="c8 c16 c26"><span class="c1"></span></p><ul class="c5 lst-kix_3zg7cputjo79-2"><li class="c14 c11 li-bullet-0"><span class="c2">Week 3 (4/24-4/30):</span></li></ul><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4/24-4/26: work on milestone deliverables </span></p><p class="c27"><span class="c1">&nbsp; &nbsp; &nbsp;(1-page webpage, 1-minute video, 2-3 slides). </span></p><p class="c13 c16"><span class="c1">Start working on Part 3: Faster contrast-based autofocus</span></p><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tue 4/26: milestone deliverable due</span></p><p class="c0"><span class="c1"></span></p><ul class="c5 lst-kix_3zg7cputjo79-2"><li class="c14 c11 li-bullet-0"><span class="c2">Week 4 (5/1-5/7):</span></li></ul><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Finish Part 3: Faster contrast-based autofocus by 5/2</span></p><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tues 5/3-4: work on presentation</span></p><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Thur 5/5: presentation due</span></p><p class="c0"><span class="c1"></span></p><ul class="c5 lst-kix_3zg7cputjo79-2"><li class="c14 c11 li-bullet-0"><span class="c2">Week 5 (5/8-5/14):</span></li></ul><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Work on final deliverables</span></p><p class="c4"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Wed 5/11: final deliverables due </span></p><p class="c14 c16"><span class="c1">&nbsp; &nbsp; &nbsp;(1-2 minute video, 2-3 pages webpage, peer review form)</span></p><p class="c0"><span class="c1"></span></p><ul class="c5 lst-kix_3zg7cputjo79-0"><li class="c4 c11 li-bullet-0"><span class="c2">Resources</span></li></ul><ul class="c5 lst-kix_3zg7cputjo79-1 start"><li class="c13 c11 li-bullet-0"><span>We will be using our code from project 3-2 and the starter code from the Lens Simulator project from Spring 2016: </span><span class="c19"><a class="c20" href="https://www.google.com/url?q=https://cs184.eecs.berkeley.edu/sp16/article/19&amp;sa=D&amp;source=editors&amp;ust=1649551995865417&amp;usg=AOvVaw2vh2hfPOB7rdSlhFqMeTIc">https://cs184.eecs.berkeley.edu/sp16/article/19</a></span></li><li class="c13 c11 li-bullet-0"><span>A Realistic Camera Model for Computer Graphics: &#8203;&#8203;</span><span class="c19"><a class="c20" href="https://www.google.com/url?q=https://www.cs.utexas.edu/~fussell/courses/cs395t/lens.pdf&amp;sa=D&amp;source=editors&amp;ust=1649551995865843&amp;usg=AOvVaw1Kzgtpy_wDXXFxHP0EG71t">https://www.cs.utexas.edu/~fussell/courses/cs395t/lens.pdf</a></span></li><li class="c13 c11 li-bullet-0"><span>Caustics and specular reflection models for spherical objects and lenses: </span><span class="c19"><a class="c20" href="https://www.google.com/url?q=https://link.springer.com/content/pdf/10.1007/BF01952422.pdf&amp;sa=D&amp;source=editors&amp;ust=1649551995866121&amp;usg=AOvVaw1pykqEGpRqqEHQRUpnPLkk">https://link.springer.com/content/pdf/10.1007/BF01952422.pdf</a></span></li><li class="c13 c11 li-bullet-0"><span>Shape from Focus System: </span><span class="c19"><a class="c20" href="https://www.google.com/url?q=https://www1.cs.columbia.edu/CAVE/publications/pdfs/Nayar_CVPR92.pdf&amp;sa=D&amp;source=editors&amp;ust=1649551995866383&amp;usg=AOvVaw2JZEfzdzYII5D8vjRmToT0">https://www1.cs.columbia.edu/CAVE/publications/pdfs/Nayar_CVPR92.pdf</a></span></li><li class="c13 c11 li-bullet-0"><span>We will be using MacOS and Windows laptops to render.</span></li></ul><p class="c17"><span class="c1"></span></p></body></html>